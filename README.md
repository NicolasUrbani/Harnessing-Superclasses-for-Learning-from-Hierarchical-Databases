# Harnessing Superclasses for Learning from Hierarchical Databases
*Nicolas URBANI, Sylvain ROUSSEAU, Yves GRANDVALET, Leonardo TANZI*

This repository contains the source code for our article "*Harnessing Superclasses for Learning from Hierarchical Databases*".

**Note: We aim to produce more comprehensive instructions for running the code. If you have any questions, do not hesitate to contact us.**



## Paper Links
- Arxiv: soon 
- HAL: soon
- ECML-PKDD Procedings: https://link.springer.com/book/10.1007/978-3-031-70359-1


## Requirements
This code uses MlFlow, Pytorch Lightning, Torchmetrics and Hydra for configuration.

Dependencies are provided in the `requirements.txt` file.

## Datasets

- For ImageNet, we used the version with the images splits in the train, test, val folders containing a folder for every class, with each folder following the nXXXXXXX format.
- For iNaturalist, we used the same setup as https://github.com/fiveai/making-better-mistakes
- For TinyImageNet, there is nothing to do, it is downloaded automatically from HuggingFace

## Running the Code

For running the experiment, an active MlFlow tracking server is necessary. After MLflow installation, `mlflow ui` and be used for setting both a visualization server and tracking server for MlFlow.

Due to the way hydra is integrated, training and evaluation script need to be run with the command `python -m src.FILENAME`.
Run parameters are done using Hydra, default configuration files and available options are provided in the `configs/` folder.
If not defined, configuration items will be set to the defaults (defined in the `config/` folder too)
For running the training, here is an example running command:

`python -m src.trainer dataset=inaturalist_autoaugment_subset optimizer.lr=1e-4 lr_scheduler=cosine_annealing loss=hierarchical_power loss.decay=0.9 trainer.max_epochs=100 trainer.ngpus=4 model=resnet50_pretrained dataset.datasets.reduction_factor=32 dataset.datasets.seed=42 experiment_name=hierarchical_power lr_scheduler.T_max=100`

- If the MLFlow does not run on port 5000 or in the same machine, it is possible to change the uri in the configuration like this: `logger.tracking_uri=http://[URI]:[port]`
- For dataset subsets, the provided reduction factor indicate by how much it will divide the number of samples in the training dataset i.e. 32 -> 1/32th of the training samples.
- The script automatically detect which GPU are not in use and select them, it selects as much GPUs as indicated by `trainer.ngpus` (by default, 1)

At the end of training, models are saved as MLFlow artifacts.

## Configuration

The `config/machine` allow defining user and machine specific configuration. Files need to follow this format: `[USERNAME]@[HOSTNAME].yaml`

## Evaluation and Visualization

The `src/evaluate.py` provides a blueprint to evaluate the trained models on multiple metrics and to record those metrics in a file.
The `src/visualize.py` file has examples methods to visualize metrics from MLFlow and the files generated by the evaluation methods.

`python -m src.visualize entrypoint=method_name`


## Source code for the ECML submission

https://www.dropbox.com/scl/fo/u333ex8laiyhhphdgze8c/h?rlkey=iuqgkgxz7ng296z3omq9icsvd&dl=0

## LICENCE

This source code is distributed under the MIT license.